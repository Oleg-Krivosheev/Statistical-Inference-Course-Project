---
title: "Essay on the Exponential Distribution"
author: Oleg Krivosheev
output:
  pdf_document: default
  html_document:
    keep_md: true
---

```{r global_options, include=FALSE}
library(knitr)
opts_chunk$set(fig.width=8, fig.height=3.2, warning=FALSE, message=FALSE)
```

## Overview

In this project we will study the exponential distribution. This distribution is characterised by single parameter
$\lambda$. We will simulate the exponential distribution in **R** and compare it with
the Central Limit Theorem.
Exponential distribution has mean equal to 1/$\lambda$,
and the standard deviation is 1/$\lambda$ as well.
$\lambda$ = 0.2 will be used throughout the simulation.
We will investigate the distribution of averages of 40 exponentials, and
distribution size would be equal to a thousand simulations.

```{r, echo=FALSE}
check_and_install <- function( packname ) { # given package name, check installation, install if not found
    if ( packname %in% rownames(installed.packages()) == FALSE ) {
        install.packages( packname )
    }
}

check_and_install("ggplot2")
check_and_install("data.table")

require(ggplot2)
require(data.table) # superior in all ways to the data frame
```

## Simulation

We set parameters and sample 1000 cases wih 40 exponentials each. We store results into a
matrix and then compute mean and variance for those exponentials.

```{r, echo=TRUE}
set.seed(223456L) # to ensure reproducability
```

```{r, echo=TRUE}
n        <- 40L  # number of exponentials
lambda   <- 0.2  # exponential parameter - rate
nof_sims <- 1000L # number of simulations

# distribution of sims as a matrix
exp.dist <- matrix(data = rexp(n * nof_sims, lambda), nrow = nof_sims)
exp.smpl <- data.table(means = apply(exp.dist, 1, mean), variance = apply(exp.dist, 1, var))
```

```{r, echo=FALSE}
nr <- nrow(exp.smpl)
nc <- ncol(exp.smpl)
```

We simulated the all cases of 40 exponentials, and computed mean and put it in the data table of the length
`r nr`. We have `r nc` observables in the data table - sampled mean and sampled variance.

## Sample Mean versus Theoretical Mean

Theoretical mean of the exponential distribution $\mu$ is inverse of
the $\lambda$ and could be easily computed.

$\mu= \frac{1}{\lambda}$

```{r, echo=FALSE}
mu <- 1/lambda
```

In our case the theoretical mean value is equal to `r mu`. Lets compare it to the sampled mean value *m*.

```{r, echo=TRUE}
m <- round(mean(exp.smpl$means), 3)
```

The sample mean value is equal to `r m`. One can see that the expected mean and sampled mean are very close. We plot the mean histogram alongside with the theoretical mean (purple line)
and sampled mean (green line).

```{r means_distribution, echo=FALSE}
g <- ggplot(exp.smpl, aes(x = means));
g <- g + geom_histogram(aes(y = ..density..), colour = "black", fill = "blue", binwidth = 0.2)
g <- g + geom_vline(xintercept = mu, size = 1.0, colour = "purple")
g <- g + geom_vline(xintercept = m, size = 1.0, colour="green")
print(g)
```

## Sample Variance versus Theoretical Variance

Theoretical standard deviation of the exponential distribution $\sigma$ is
also inverse of the $\lambda$, and distribution variance as well is expressed via
$\lambda$.

$\sigma = \frac{1}{\lambda}$

$Var = \sigma^2 = \frac{1}{\lambda^2}$

```{r, echo=FALSE}
sigma2 <- 1.0/(lambda*lambda)
```

Theoretical variance is equal to `r sigma2`. Lets compute sample variance as mean
value of the variance column in our data.table.

```{r, echo=TRUE}
s2 <- round(mean(exp.smpl$variance), 3)
```

Comparing theoretical variance of  `r sigma2` to sampled variance `r s2`, one
can see they are very close. We plot variance distribution together with
theoretical (purple) and sampled (green) variance

```{r variance_distribution, echo=FALSE}
g <- ggplot(exp.smpl, aes(x = variance));
g <- g + geom_histogram(aes(y = ..density..), colour = "black", fill = "blue")
g <- g + geom_vline(xintercept = sigma2, size = 1.0, colour = "purple")
g <- g + geom_vline(xintercept = s2, size = 1.0, colour="green")
print(g)
```

Another way to look at variance comparison is to compute variance of the
sample versus distribution sample variance.
Theoretical one for a given sample size *n* is equal to distribution
variance divided by *n*.  Variance of the sample
could be computed applying *var()* function to the sampled vector of means.

$Var_n = \frac{\sigma^2}{n}$

```{r, echo=TRUE}
v2 <- round(var(exp.smpl$means), 3)
vn <- sigma2/n
```

Value we got are `r v2` for theoretical and `r vn` for sampled, and one can
see they are very close to each other.

## Distribution

For inspection and comparison we plot means distribution together with
overlapping theoretical gaussian curve (red) as well as smooth sample distribution curve (cyan).
From visual inspection those curves are very close to each other.

```{r normal_distribution, echo=FALSE}
g <- ggplot(exp.smpl, aes(x = means));
g <- g + geom_histogram(aes(y = ..density..), colour = "black", fill = "blue", binwidth = 0.2)
g <- g + geom_density(colour="cyan", size = 1.0)
g <- g + stat_function(fun = dnorm, geom = "line",
                       args = list(mean = mu, sd = sqrt(sigma2/n)),
                       size = 1.0, col = "red")
g <- g + geom_vline(xintercept = mu, size = 1.0, colour="red") + geom_vline(xintercept = m, size = 1.0, colour="cyan")
print(g)
```

```{r, echo=FALSE}
# qqline(exp.smpl$means)
# qqnorm(exp.smpl$means)
gg_qq <- function(x, distribution = "norm", ..., line.estimate = NULL, conf = 0.95,
                  labels = NULL) {
  q.function <- eval(parse(text = paste0("q", distribution)))
  d.function <- eval(parse(text = paste0("d", distribution)))
  x <- na.omit(x)
  ord <- order(x)
  n <- length(x)
  P <- ppoints(length(x))
  df <- data.frame(ord.x = x[ord], z = q.function(P, ...))

  if(is.null(line.estimate)){
    Q.x <- quantile(df$ord.x, c(0.25, 0.75))
    Q.z <- q.function(c(0.25, 0.75), ...)
    b <- diff(Q.x)/diff(Q.z)
    coef <- c(Q.x[1] - b * Q.z[1], b)
  } else {
    coef <- coef(line.estimate(ord.x ~ z))
  }

  zz <- qnorm(1 - (1 - conf)/2)
  SE <- (coef[2]/d.function(df$z)) * sqrt(P * (1 - P)/n)
  fit.value <- coef[1] + coef[2] * df$z
  df$upper <- fit.value + zz * SE
  df$lower <- fit.value - zz * SE

  if(!is.null(labels)){
    df$label <- ifelse(df$ord.x > df$upper | df$ord.x < df$lower, labels[ord],"")
    }

  p <- ggplot(df, aes(x=z, y=ord.x)) +
    geom_point() +
    geom_abline(intercept = coef[1], slope = coef[2]) +
    geom_ribbon(aes(ymin = lower, ymax = upper), alpha=0.2)
  if(!is.null(labels)) {
    p <- p + scale_x_continuous(name=labels[1]) + scale_y_continuous(name=labels[2])
  }

  print(p)
  coef
}
```

We provide Quantile-Quantile Plot for determining if two data sets come
from populations with a common distribution. One curve is a linear
one computed from theoretical distribution. Another one is computed from
sampled means distribution. We could see that points from sample fall appproximately
along the theoretical reference line.

```{r qq_plot, echo=FALSE}
gg_qq(exp.smpl$means, labels = c("Theoretical Quantiles", "Sample Quantiles"))
```

## Appendix A

Markdown code is available from the **GitHub** repository at *https://github.com/Oleg-Krivosheev/Statistical-Inference-Course-Project/one.Rmd*

Q-Q plots are described in detail at *http://www.itl.nist.gov/div898/handbook/eda/section3/qqplot.htm*.

Code for **ggplot2** Q-Q plot was taken from *http://stackoverflow.com/a/27191036/4044696*
and modified by the author.

## Appendix B

We recompute and replot distributions here doing fine sampling with 100,000 samples instead
of original 1,000 ones. As one can see, the result is even more conforming to the
gaussian distribution.

```{r, echo=TRUE}
set.seed(123456L) # to ensure reproducability
```

```{r, echo=TRUE}
nof_sims <- 100000L # number of simulations

exp.dist <- matrix(data = rexp(n * nof_sims, lambda), nrow = nof_sims)
exp.smpl <- data.table(means = apply(exp.dist, 1, mean), variance = apply(exp.dist, 1, var))

m <- round(mean(exp.smpl$means), 3)
```

Dsitrbution plot, using same conventions as before.

```{r hidef_means_distribution, echo=FALSE}
g <- ggplot(exp.smpl, aes(x = means));
g <- g + geom_histogram(aes(y = ..density..), colour = "black", fill = "blue", binwidth = 0.2)
g <- g + geom_density(colour="cyan", size = 1.0)
g <- g + stat_function(fun = dnorm, geom = "line",
                       args = list(mean = mu, sd = sqrt(sigma2/n)),
                       size = 1.0, col = "red")
g <- g + geom_vline(xintercept = mu, size = 1.0, colour="red") + geom_vline(xintercept = m, size = 1.0, colour="cyan")
print(g)
```

Mean values are prety much indistibguishable  from each other.

Q-Q plot, again, same conventions are used.

```{r hidef_qq_plot, echo=FALSE}
gg_qq(exp.smpl$means, labels = c("Theoretical Quantiles", "Sample Quantiles"))
```
