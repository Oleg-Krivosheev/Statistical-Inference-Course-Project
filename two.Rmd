---
title: "Reproducible Research: Peer Assessment 1"
author: Oleg Krivosheev
output:
  html_document:
    keep_md: true
---

Peer Assessment 1
=================

This document fulfills the requirements for the peer assessment 1 assignment,
for Coursera course [Reproducible Research](https://class.coursera.org/repdata-035).

## Introduction

We take the problem description verbatim from the original document.

> It is now possible to collect a large amount of data about personal
> movement using activity monitoring devices such as a
> [Fitbit](http://www.fitbit.com), [Nike
> Fuelband](http://www.nike.com/us/en_us/c/nikeplus-fuelband), or
> [Jawbone Up](https://jawbone.com/up). These type of devices are part of
> the "quantified self" movement -- a group of enthusiasts who take
> measurements about themselves regularly to improve their health, to
> find patterns in their behavior, or because they are tech geeks. But
> these data remain under-utilized both because the raw data are hard to
> obtain and there is a lack of statistical methods and software for
> processing and interpreting the data.
>
> This assignment makes use of data from a personal activity monitoring
> device. This device collects data at 5 minute intervals through out the
> day. The data consists of two months of data from an anonymous
> individual collected during the months of October and November, 2012
> and include the number of steps taken in 5 minute intervals each day.

## Data

Data archive is included into the repository. As an alternative, data could
be downloaded from [Activity monitoring data](https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip).

Data description taken verbatim from the assignment.

> The variables included in this dataset are:
>
> * **steps**: Number of steps taking in a 5-minute interval (missing
>     values are coded as `NA`)
>
> * **date**: The date on which the measurement was taken in YYYY-MM-DD
>     format
>
> * **interval**: Identifier for the 5-minute interval in which
>     measurement was taken
>
>
> The dataset is stored in a comma-separated-value (CSV) file and there
> are a total of 17,568 observations in this
> dataset.

## Assignment

There are multiple parts for this assignment. This document will answer all
questions raised as part of an assignment. Document to be processed by **knitr**
and output will be valid HTML file. **R** code in the document will be echoed
so reviewer shall be able to read the code. Each section below will answer one
or more questions raised in the assignment.

## Loading required **R** packages

First, we check if all necessary packages are installed. If not, they
will be installed and loaded.

```{r, echo=TRUE}
check_and_install <- function( packname ) {
    # given package name, check if it is installed
    # if not, download and install
    if ( packname %in% rownames(installed.packages()) == FALSE ) {
        install.packages( packname )
    }
}

check_and_install("data.table")
check_and_install("xtable")
check_and_install("ggplot2")

require("data.table")
require("xtable")
require("ggplot2")
```

## Loading and preprocessing the data

Data as a ZIP archive are located in the same directory as the **R** markdown. Thus,
first we unpack archive and extract CSV file.
Then, we read it and check for consistency. Last, we convert date string to
*Date* and set primary key. Essential features of the [data.table](https://cran.r-project.org/web/packages/data.table/index.html)
package will be used.

### Unpacking and loading data

```{r, echo=TRUE}
unzip("activity.zip", "activity.csv")

dt <- fread("activity.csv")
str(dt)
head(dt)
tail(dt)
```

One can see we have three columns as *int*, *character* and *int*.

### Check for consistency

```{r, echo=TRUE}
dims <- dim(dt)

if (dims[1] != 17568) {
    stop("Bad number of rows, should be 17568, bailing out!")
}

if (dims[2] != 3) {
    stop("Bad number of columns, should be 3, bailing out!")
}
```

If we make it so far, data are consistent with our expectations.

### Data preprocessing

First, we prefer to convert second column to proper date.

```{r, echo=TRUE}
dt <- dt[ , date := as.Date(date, "%Y-%m-%d")]
```

Second, we make *steps* column a numeric, for easy dealing with
data imputing later.

```{r, echo=TRUE}
dt <- dt[ , steps := as.numeric(steps)]

str(dt)
head(dt)
tail(dt)
```

Last step is to set *date* as primary key for speedy evaluation

```{r, echo=TRUE}
setkey(dt, date)
str(dt)
```

## What is mean total number of steps taken per day?

Here we will try to answer several question, taken verbatim from the assignment.

> ### Calculate the total number of steps taken per day

We will group data table by date, and then aggregate the number of steps.

```{r, echo=TRUE}
dt.steps_by_date <- dt[, sum(steps), by=date]
setnames(dt.steps_by_date, "V1", "steps")

str(dt.steps_by_date)
head(dt.steps_by_date)
tail(dt.steps_by_date)
```

> ### Make a histogram of the total number of steps taken each day

To make a histogram, we will use **ggplot2** package functionality.
We will make it a gradient plot to look a bit nicer. Also, we would
like to see how bin width affects histrogram appearance.

First, low resolution histogram with bin width equal to 1000.

```{r histo_nof_steps_each_day_low, fig.width=8, fig.height=6, echo=TRUE}
p <- ggplot(dt.steps_by_date, aes(x = steps)) +
       geom_histogram(alpha=0.3, binwidth=1000,
                     col="red",
                     aes(fill=..count..)) +
       scale_fill_gradient("Count", low = "blue", high = "red") +
       labs(title="Histogram of the total number of steps taken each day") +
       labs(x="Total number of steps", y="Day count")
print(p)
```

Then, medium resolution histogram with bin width equal to 750.

```{r histo_nof_steps_each_day_med, fig.width=8, fig.height=6, echo=TRUE}
p <- ggplot(dt.steps_by_date, aes(x = steps)) +
       geom_histogram(alpha=0.3, binwidth=750,
                     col="red",
                     aes(fill=..count..)) +
       scale_fill_gradient("Count", low = "blue", high = "red") +
       labs(title="Histogram of the total number of steps taken each day") +
       labs(x="Total number of steps", y="Day count")
print(p)
```

Last histogram is a fine one, with bin width equal to 500.

```{r histo_nof_steps_each_day_high, fig.width=8, fig.height=6, echo=TRUE}
p <- ggplot(dt.steps_by_date, aes(x = steps)) +
       geom_histogram(alpha=0.3, binwidth=500,
                     col="red",
                     aes(fill=..count..)) +
       scale_fill_gradient("Count", low = "blue", high = "red") +
       labs(title="Histogram of the total number of steps taken each day") +
       labs(x="Total number of steps", y="Day count")
print(p)
```

> ### Calculate and report the mean and median of the total number of steps taken per day

We will calculate the mean and median of the total number of steps taken per day.
Because data still has *NA* values, we will filter them out.
To make a nice table, we will be using [xtable](https://cran.r-project.org/web/packages/xtable/index.html)
package.

First, we make data table *tbl* filtering out *NA* values and computing mean and median.

```{r, echo=TRUE}
tbl <- dt.steps_by_date[, list(N = .N,  mean = mean(steps, na.rm=TRUE), median = median(steps, na.rm=TRUE))]
str(tbl)
```

Then we print *tbl* as a nice embedded HTML table.

```{r results="asis", echo=TRUE}
print(xtable(tbl), type="html", include.rownames=FALSE)
```

## What is the average daily activity pattern?

There are two questions to be answered in this chapter of the assignment.

> ### Make a time series plot of the 5-minute interval (x-axis) and the average number of steps taken, averaged across all days (y-axis)

First, we make new data table, grouped by interval with average number of steps taken.
Of course, *NA* values will be filtered out.

```{r, echo=TRUE}
dt.steps_by_interval <- dt[, list(mean = mean(steps, na.rm=TRUE)), by=interval]
str(dt.steps_by_interval)
```

Now making linear plot, again using **ggplot2** as plotting library.

```{r ave_nof_steps_taken, echo=TRUE, fig.width=8, fig.height=6}
p <- ggplot(dt.steps_by_interval, aes(x=interval, y=mean)) +
	geom_line(size=1, colour="#CC6666") +
    labs(title="Average number of steps per interval") +
    labs(x="Interval", y="Average number of steps")
print(p)
```

> ### Which 5-minute interval, on average across all the days in the dataset, contains the maximum number of steps?

To find this value, first we sort our data table by average number of steps in
the descending order, and thus first row will contain asked value in the
*interval* column.

```{r, echo=TRUE}
q <- dt.steps_by_interval[order(-mean)]
str(q)
max_interval <- q[1, interval]
```

The 5-minute interval, on average across all the days in the dataset,
with the largest number of steps is `r max_interval`.
It is consistent with the displayed graph.

## Imputing missing values

There are a number of days/intervals where there are missing
values (coded as `NA`). The presence of missing days may introduce
bias into some calculations or summaries of the data.

> ### Calculate and report the total number of missing values in the dataset

We use **is.na()** function to get logical vector of missing values.
Then we sum it to produce asked value.

```{r, echo=TRUE}
q <- is.na(dt$steps)
mia_steps <- sum(q)
```

Thus, total number of missing values is equal to `r mia_steps`.

Just in case, checking *NA* in the *date* and *interval* columns

```{r, echo=TRUE}
q <- is.na(dt$date)
mia_date <- sum(q)
```

Number of missing dates is equal to `r mia_date`.

```{r, echo=TRUE}
q <- is.na(dt$interval)
mia_interval <- sum(q)
```

Number of missing intervals is equal to `r mia_interval`.
Thus, we believe there are no missing dates and intervals.

> ### Devise a strategy for filling in all of the missing values in the dataset.

We will use very simple strategy. For each missing value we will replace it with
mean value for the same 5-minute interval computed over all data table.

First, we make helper data table with only two columns, interval versus
average number of steps per interval, with *NA* values removed.

```{r, echo=TRUE}
dt.med = dt[, list(mean=mean(steps, na.rm=TRUE)), by=interval]
setkey(dt.med, interval)
str(dt.med)
```

> ### Create a new dataset that is equal to the original dataset but with the missing data filled in.

Make a copy of the original data table, which is going to be filled with imputed values.

```{r, echo=TRUE}
dt.imp <- copy(dt)
str(dt.imp)
tables()
```

Now we have two data tables in the memory (along the other working tables).

We will search in a loop for *NA*, and as soon sa it is found,
we get interval and select mean value of steps from the helper
data table. Value will be rounded to represent ordinal number of steps.
Rounding will keep data reasonable, but it will slightly affect mean, median
and similar values. As an alternative, one might consider imputing unaltered
mean values. It is possible because we converted *steps* into *numeric*.

```{r, echo=TRUE}
for (k in seq_len(nrow(dt.imp))) {
    if (is.na(dt.imp$steps[k])) {
        i <- dt.imp$interval[k]
        q <- dt.med[interval == i]
        dt.imp$steps[k] = round(q$mean)
    }
}

#write.csv(dt.imp, file = "imputed.csv")
```

**NB:** Ought to find a better way for such operation.

Now lets check new data table has no *NA* values.

```{r, echo=TRUE}
q <- is.na(dt.imp$steps)
sum(q)
```

Just in case, check original data table still contains *NA* values.

```{r, echo=TRUE}
q <- is.na(dt$steps)
sum(q)
```

> ### Make a histogram of the total number of steps taken each day and Calculate and report the **mean** and **median** total number of steps taken per day. Do these values differ from the estimates from the first part of the assignment?

We will use new data table to compute the total number of steps taken each day.

```{r, echo=TRUE}
dt.imp.steps_by_date <- dt.imp[, sum(steps), by=date]
setnames(dt.imp.steps_by_date, "V1", "steps")

str(dt.imp.steps_by_date)
head(dt.imp.steps_by_date)
tail(dt.imp.steps_by_date)
```

Plotting new histogram, first low resolution

```{r histo_nof_steps_each_day_imp_low, fig.width=8, fig.height=6, echo=TRUE}
p <- ggplot(dt.imp.steps_by_date, aes(x = steps)) +
       geom_histogram(alpha=0.3, binwidth=1000,
                     col="red",
                     aes(fill=..count..)) +
       scale_fill_gradient("Count", low = "blue", high = "red") +
       labs(title="Imputed histogram of the total number of steps taken each day") +
       labs(x="Total number of steps", y="Day count")
print(p)
```

then medium

```{r histo_nof_steps_each_day_imp_med, fig.width=8, fig.height=6, echo=TRUE}
p <- ggplot(dt.imp.steps_by_date, aes(x = steps)) +
       geom_histogram(alpha=0.3, binwidth=750,
                     col="red",
                     aes(fill=..count..)) +
       scale_fill_gradient("Count", low = "blue", high = "red") +
       labs(title="Imputed histogram of the total number of steps taken each day") +
       labs(x="Total number of steps", y="Day count")
print(p)
```

and, finally, high resolution graph.

```{r histo_nof_steps_each_day_imp_high, fig.width=8, fig.height=6, echo=TRUE}
p <- ggplot(dt.imp.steps_by_date, aes(x = steps)) +
       geom_histogram(alpha=0.3, binwidth=500,
                     col="red",
                     aes(fill=..count..)) +
       scale_fill_gradient("Count", low = "blue", high = "red") +
       labs(title="Imputed histogram of the total number of steps taken each day") +
       labs(x="Total number of steps", y="Day count")
print(p)
```

As before, we make table of mean and median.

```{r, echo=TRUE}
tbl.imp <- dt.imp.steps_by_date[, list(N = .N,  mean = mean(steps, na.rm=TRUE), median = median(steps, na.rm=TRUE))]
str(tbl.imp)
```

Then we print *tbl.imp* as a nice embedded HTML table.

```{r results="asis", echo=TRUE}
print(xtable(tbl.imp), type="html", include.rownames=FALSE)
```

Now, we combine old and new table to present them together

```{r, echo=TRUE}
tbl.sum <- rbind(tbl, tbl.imp)
row.names(tbl.sum) <- c("Original", "Imputed")
```

and print it

```{r results="asis", echo=TRUE}
print(xtable(tbl.sum), type="html", include.rownames=TRUE)
```

Apparently, they are different from non-imputed data, but only slightly.

> ### What is the impact of imputing missing data on the estimates of the total daily number of steps?

The impact of our strategy is very slight change in the mean and median
value of the imputed data table vs original one. The reason for difference being very small
is quite simple - selected strategy by replacing missing values with mean pretty
much guarantees that mean and median would be very close to the original one.

From the other hand, from histograms one can see there is now a lot more days having
particular number of steps taken, so *count* is going up.
This was an expected development, because now there are a lot more days to
contribute to the particular histogram bins.

## Are there differences in activity patterns between weekdays and weekends?

We will use imputed data table for computations and graphs to answer stated question.

> ### Create a new factor variable in the dataset with two levels -- "weekday" and "weekend" indicating whether a given date is a weekday or weekend day.

First, we make character vector with our two factors which match accepted
weekend/weekday numbering scheme (week start with Sunday and ends on Saturday).

```{r, echo=TRUE}
thedays <- c("weekend", rep("weekday",5), "weekend")
print(thedays)
```

Then we add another column to the imputed data table with factors as
observable. For that, we use *date*, coerse it into POSIXlt type,
take *wday* from ut which would be numeric ranging from 0 to 6.
We add one to have range from 1 to 7, use it as an index to the
*thedays* array and finally treat it all as a factor. Ugh!

But it fits into one line...

```{r, echo=TRUE}
dt.imp[, wd := as.factor(thedays[as.POSIXlt(dt.imp$date)$wday + 1])]
str(dt.imp)
```

One can see we have now two-level factor as a forth column. To check
if first date is really a weekday, we could visit [2012-10-01](http://www.dayoftheweek.org/?m=October&d=1&y=2012&go=Go#axzz3utuUEy1w)
on this page, and indeed that day was Monday.

Count number of weekdays and weekends in data table.

```{r, echo=TRUE}
q <- dt.imp$wd == "weekday"
weekdays <- sum(q)
q <- dt.imp$wd == "weekend"
weekends <- sum(q)
totaldays <- weekends+weekdays
```

So we have `r weekdays` weekdays and `r weekends` weekends in our data table
for a total of `r totaldays` (which, in turn, is equal to the number of observations
in the data table).

> ### Make a panel plot containing a time series plot of the 5-minute interval (x-axis) and the average number of steps taken, averaged across all weekday days or weekend days (y-axis).

Aggregate the average number of steps taken by 5-minute interval.
Use the imputed values in the `steps` variable.

```{r}
dt.imp.meansteps <- dt.imp[, list(mean = mean(steps, na.rm=TRUE)), by = list(wd, interval)]
```

Plot two time series (one for weekdays and the other for weekends) of the 5-minute intervals and average number of steps taken (using imputed values).
We again use **ggplot2*, with facets, to make multy-graph plot.

```{r time_series_average_steps_by_interval_wd_imp, echo=TRUE }
p <- ggplot(dt.imp.meansteps, aes(x=interval, y=mean, color=wd)) +
	 facet_wrap(~wd, nrow=2) +
	 geom_line(size = 1) +
     labs(title="Time series of the mean number of steps taken per interval and day type") +
     labs(x="Interval", y="Mean number of steps") +
	 theme(legend.position="none")
print(p)
```

As on can see, during weekend people tend to walk less, but in more uniform pattern.

## Conclusion

That's it, folks.
